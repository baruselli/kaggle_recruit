{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252108\n"
     ]
    }
   ],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import *\n",
    "\n",
    "data = {\n",
    "    #visitors\n",
    "    'tra': pd.read_csv('./input/air_visit_data.csv',parse_dates=[\"visit_date\"]),\n",
    "    #reservations\n",
    "    'ar': pd.read_csv('./input/air_reserve.csv',parse_dates=[\"visit_datetime\",\"reserve_datetime\"]),\n",
    "    'hr': pd.read_csv('./input/hpg_reserve.csv',parse_dates=[\"visit_datetime\",\"reserve_datetime\"]),\n",
    "    #store info\n",
    "    'as': pd.read_csv('./input/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('./input/hpg_store_info.csv'),\n",
    "    #air<->hpg\n",
    "    'id': pd.read_csv('./input/store_id_relation.csv'),\n",
    "    #days\n",
    "    'hol': pd.read_csv('./input/date_info.csv',parse_dates=[\"calendar_date\"]), #.rename(columns={'calendar_date':'visit_date'})\n",
    "    #\n",
    "    'tes': pd.read_csv('./input/sample_submission.csv'),\n",
    "    }\n",
    "\n",
    "data[\"tra\"][\"visitors\"]=np.log1p(data[\"tra\"][\"visitors\"])\n",
    "data[\"tra\"][\"month\"]=data[\"tra\"].visit_date.map(lambda x: x.month)\n",
    "data[\"tra\"][\"time_numeric\"]=pd.to_numeric(data[\"tra\"].visit_date-data[\"tra\"].visit_date.min())/1e12\n",
    "data[\"tra\"][\"time_numeric\"].fillna(0,inplace=True)\n",
    "data[\"tra\"][\"weights\"]=np.exp(data[\"tra\"][\"time_numeric\"]/data[\"tra\"][\"time_numeric\"].max())\n",
    "\n",
    "print(len(data[\"tra\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(np.log(y+1), np.log(pred+1))**0.5\n",
    "def RMSE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data categorizing to reduce space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tra 4.668583869934082\n",
      "ar 8.898050308227539\n",
      "hr 192.67313385009766\n",
      "as 0.23502159118652344\n",
      "hs 1.3301172256469727\n",
      "id 0.022129058837890625\n",
      "hol 0.039612770080566406\n",
      "tes 2.9315261840820312\n",
      "total 210.79817485809326\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "data[\"tra\"][\"air_store_id\"]=data[\"tra\"][\"air_store_id\"].astype('category')\n",
    "total=0\n",
    "for k,v in data.items():\n",
    "    size_k=sys.getsizeof(data[k])/1024/1024\n",
    "    total+=size_k\n",
    "    print(k,size_k)\n",
    "print(\"total\",total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"tra\"][\"air_store_id\"]=data[\"tra\"][\"air_store_id\"].astype('category')\n",
    "data[\"tra\"][\"month\"]=data[\"tra\"][\"month\"].astype('category')\n",
    "data[\"as\"][\"air_store_id\"]=data[\"as\"][\"air_store_id\"].astype('category')\n",
    "data[\"as\"][\"air_genre_name\"]=data[\"as\"][\"air_genre_name\"].astype('category')\n",
    "data[\"as\"][\"air_area_name\"]=data[\"as\"][\"air_area_name\"].astype('category')\n",
    "data[\"hs\"][\"hpg_store_id\"]=data[\"hs\"][\"hpg_store_id\"].astype('category')\n",
    "data[\"hs\"][\"hpg_genre_name\"]=data[\"hs\"][\"hpg_genre_name\"].astype('category')\n",
    "data[\"hs\"][\"hpg_area_name\"]=data[\"hs\"][\"hpg_area_name\"].astype('category')\n",
    "data[\"ar\"][\"air_store_id\"]=data[\"ar\"][\"air_store_id\"].astype('category')\n",
    "data[\"hr\"][\"hpg_store_id\"]=data[\"hr\"][\"hpg_store_id\"].astype('category')\n",
    "data[\"id\"][\"hpg_store_id\"]=data[\"id\"][\"hpg_store_id\"].astype('category')\n",
    "data[\"id\"][\"air_store_id\"]=data[\"id\"][\"air_store_id\"].astype('category')\n",
    "data[\"hol\"][\"day_of_week\"]=data[\"hol\"][\"day_of_week\"].astype('category')\n",
    "data[\"hol\"][\"holiday_flg\"]=data[\"hol\"][\"holiday_flg\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tra 4.668583869934082\n",
      "ar 2.323484420776367\n",
      "hr 51.20259189605713\n",
      "as 0.13867950439453125\n",
      "hs 0.6168069839477539\n",
      "id 0.032466888427734375\n",
      "hol 0.005854606628417969\n",
      "tes 2.9315261840820312\n",
      "total 61.91999435424805\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "for k,v in data.items():\n",
    "    size_k=sys.getsizeof(data[k])/1024/1024\n",
    "    total+=size_k\n",
    "    print(k,size_k)\n",
    "print(\"total\",total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"tes\"][[\"store_id\",\"time\"]]=data[\"tes\"][\"id\"].str.split(\"_2017\",expand=True)\n",
    "data[\"tes\"][\"time\"]=\"2017\"+data[\"tes\"][\"time\"]\n",
    "from dateutil import parser\n",
    "data[\"tes\"][\"time\"] = pd.to_datetime(data[\"tes\"][\"time\"])\n",
    "#data[\"tes\"][\"kind\"]=data[\"tes\"][\"id\"].str.split(\"_\",expand=True)[0] #they are all air type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data[\"tes\"].dtypes)\n",
    "#data[\"tes\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I add the test dates/stores to the train df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates=data[\"tes\"][\"time\"].unique()\n",
    "test_stores=data[\"tes\"][\"store_id\"].unique()\n",
    "\n",
    "days = pd.DataFrame({'visit_date':test_dates})\n",
    "stores = pd.DataFrame({'air_store_id':test_stores})\n",
    "stores['key'] = 0\n",
    "days['key'] = 0\n",
    "days_and_stores = days.merge(stores, how='left', on = 'key')\n",
    "days_and_stores.drop('key',1, inplace=True)\n",
    "days_and_stores\n",
    "\n",
    "data[\"tra_test\"]=data[\"tra\"].append(days_and_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32019\n",
      "252108\n",
      "284127\n"
     ]
    }
   ],
   "source": [
    "print(len(days_and_stores))\n",
    "print(len(data[\"tra\"]))\n",
    "print(len(data[\"tra_test\"]))\n",
    "#data[\"tra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_date='2017-3-15'\n",
    "\n",
    "def train_test_eval(df,cut_date):\n",
    "    df_train=df[df.visitors.notnull()][df[\"visit_date\"]<cut_date]        #train\n",
    "    df_test= df[df.visitors.notnull()][df[\"visit_date\"]>= cut_date]      #test (I have data to check)\n",
    "    df_eval= df[df.visitors.isnull()]                                   #eval (for submission only, no data to check)\n",
    "    return(df_train,df_test,df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I split data[\"tra_test\"] so that al the averages are only from the training period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5e9bc92af7cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatatra_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdatatra_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdatatra_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tra_test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcut_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-ffe6bacaad55>\u001b[0m in \u001b[0;36mtrain_test_eval\u001b[1;34m(df, cut_date)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_test_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcut_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisitors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"visit_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mcut_date\u001b[0m\u001b[1;33m]\u001b[0m        \u001b[1;31m#train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdf_test\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisitors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"visit_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m \u001b[0mcut_date\u001b[0m\u001b[1;33m]\u001b[0m      \u001b[1;31m#test (I have data to check)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdf_eval\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisitors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m                                   \u001b[1;31m#eval (for submission only, no data to check)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2054\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2094\u001b[0m             \u001b[1;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2095\u001b[0m             \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2096\u001b[1;33m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2097\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2098\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(ax, key)\u001b[0m\n\u001b[0;32m   1934\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1935\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1936\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1937\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, index, **kwargs)\u001b[0m\n\u001b[0;32m   2424\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reindex'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2425\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2426\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fillna'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2402\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2403\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[1;32m-> 2404\u001b[1;33m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[0;32m   2405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2406\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   2420\u001b[0m             obj = obj._reindex_with_indexers({axis: [new_index, indexer]},\n\u001b[0;32m   2421\u001b[0m                                              \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2422\u001b[1;33m                                              copy=copy, allow_dups=False)\n\u001b[0m\u001b[0;32m   2423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2424\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   2514\u001b[0m                                                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m                                                 \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2516\u001b[1;33m                                                 copy=copy)\n\u001b[0m\u001b[0;32m   2517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   3884\u001b[0m         \u001b[1;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3885\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3886\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3888\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   2785\u001b[0m         \u001b[1;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2786\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2787\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2789\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "datatra_train,datatra_test,datatra_eval=train_test_eval(data[\"tra_test\"],cut_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join dataframes\n",
    "\n",
    "- train + store info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>month</th>\n",
       "      <th>time_numeric</th>\n",
       "      <th>weights</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>1</td>\n",
       "      <td>1123.2</td>\n",
       "      <td>1.027628</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>1</td>\n",
       "      <td>1209.6</td>\n",
       "      <td>1.029785</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>1</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>1.031946</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1</td>\n",
       "      <td>1468.8</td>\n",
       "      <td>1.036282</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id visit_date  visitors month  time_numeric   weights  \\\n",
       "0  air_ba937bf13d40fb24 2016-01-13  3.258097     1        1036.8  1.025476   \n",
       "1  air_ba937bf13d40fb24 2016-01-14  3.496508     1        1123.2  1.027628   \n",
       "2  air_ba937bf13d40fb24 2016-01-15  3.401197     1        1209.6  1.029785   \n",
       "3  air_ba937bf13d40fb24 2016-01-16  3.135494     1        1296.0  1.031946   \n",
       "4  air_ba937bf13d40fb24 2016-01-18  1.945910     1        1468.8  1.036282   \n",
       "\n",
       "  air_genre_name                 air_area_name   latitude   longitude  \n",
       "0     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599  \n",
       "1     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599  \n",
       "2     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599  \n",
       "3     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599  \n",
       "4     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tra_as\"]=data[\"tra\"].merge(data[\"as\"],on=\"air_store_id\")\n",
    "data[\"tra_as\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>genre_wht_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asian</td>\n",
       "      <td>3.512235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bar/Cocktail</td>\n",
       "      <td>2.348968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe/Sweets</td>\n",
       "      <td>2.897400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creative cuisine</td>\n",
       "      <td>2.962171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dining bar</td>\n",
       "      <td>2.642158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     air_genre_name  genre_wht_mean\n",
       "0             Asian        3.512235\n",
       "1      Bar/Cocktail        2.348968\n",
       "2       Cafe/Sweets        2.897400\n",
       "3  Creative cuisine        2.962171\n",
       "4        Dining bar        2.642158"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_mean_0=pd.DataFrame()\n",
    "#genre_mean_0[\"genre_mean\"]=data[\"tra_as\"].groupby(\"air_genre_name\").visitors.mean()\n",
    "#genre_mean_0[\"genre_median\"]=data[\"tra_as\"].groupby(\"air_genre_name\").visitors.median()\n",
    "#genre_mean_0[\"genre_min\"]=data[\"tra_as\"].groupby(\"air_genre_name\").visitors.min()\n",
    "#genre_mean_0[\"genre_max\"]=data[\"tra_as\"].groupby(\"air_genre_name\").visitors.max()\n",
    "#genre_mean_0[\"genre_std\"]=data[\"tra_as\"].groupby(\"air_genre_name\").visitors.std()\n",
    "genre_mean_0[\"genre_wht_mean\"]=data[\"tra_as\"].groupby(\"air_genre_name\").apply(lambda x: np.average(x['visitors'], weights=x['weights']))\n",
    "#genre_mean_0[\"genre_wht_mean\"]=data[\"tra_as\"].groupby(\"air_genre_name\").apply(lambda x: np.average(x['visitors']))\n",
    "\n",
    "genre_mean_0.reset_index(inplace=True)\n",
    "genre_mean_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>area_wht_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Daimyō</td>\n",
       "      <td>2.771733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Hakata Ekimae</td>\n",
       "      <td>2.857302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Imaizumi</td>\n",
       "      <td>2.668836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Momochi</td>\n",
       "      <td>2.655420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Shiobaru</td>\n",
       "      <td>2.557863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           air_area_name  area_wht_mean\n",
       "0         Fukuoka-ken Fukuoka-shi Daimyō       2.771733\n",
       "1  Fukuoka-ken Fukuoka-shi Hakata Ekimae       2.857302\n",
       "2       Fukuoka-ken Fukuoka-shi Imaizumi       2.668836\n",
       "3        Fukuoka-ken Fukuoka-shi Momochi       2.655420\n",
       "4       Fukuoka-ken Fukuoka-shi Shiobaru       2.557863"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_mean_0=pd.DataFrame()\n",
    "#area_mean_0[\"area_mean\"]=data[\"tra_as\"].groupby(\"air_area_name\").visitors.mean()\n",
    "#area_mean_0[\"area_median\"]=data[\"tra_as\"].groupby(\"air_area_name\").visitors.median()\n",
    "#area_mean_0[\"area_min\"]=data[\"tra_as\"].groupby(\"air_area_name\").visitors.min()\n",
    "#area_mean_0[\"area_max\"]=data[\"tra_as\"].groupby(\"air_area_name\").visitors.max()\n",
    "#area_mean_0[\"area_std\"]=data[\"tra_as\"].groupby(\"air_area_name\").visitors.std()\n",
    "area_mean_0[\"area_wht_mean\"]=data[\"tra_as\"].groupby(\"air_area_name\").apply(lambda x: np.average(x['visitors'], weights=x['weights']))\n",
    "area_mean_0.reset_index(inplace=True)\n",
    "area_mean_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train + day + store info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>month</th>\n",
       "      <th>time_numeric</th>\n",
       "      <th>weights</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_25e9888d30b386df</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Izakaya</td>\n",
       "      <td>Tōkyō-to Shinagawa-ku Higashigotanda</td>\n",
       "      <td>35.626568</td>\n",
       "      <td>139.725858</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fd6aac1043520e83</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Izakaya</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_64d4491ad8cdb1c6</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ee3a01f0c71a769f</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Cafe/Sweets</td>\n",
       "      <td>Shizuoka-ken Hamamatsu-shi Motoshirochō</td>\n",
       "      <td>34.710895</td>\n",
       "      <td>137.725940</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id visit_date  visitors month  time_numeric   weights  \\\n",
       "0  air_ba937bf13d40fb24 2016-01-13  3.258097     1        1036.8  1.025476   \n",
       "1  air_25e9888d30b386df 2016-01-13  3.091042     1        1036.8  1.025476   \n",
       "2  air_fd6aac1043520e83 2016-01-13  3.713572     1        1036.8  1.025476   \n",
       "3  air_64d4491ad8cdb1c6 2016-01-13  1.791759     1        1036.8  1.025476   \n",
       "4  air_ee3a01f0c71a769f 2016-01-13  2.944439     1        1036.8  1.025476   \n",
       "\n",
       "  air_genre_name                            air_area_name   latitude  \\\n",
       "0     Dining bar             Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "1        Izakaya     Tōkyō-to Shinagawa-ku Higashigotanda  35.626568   \n",
       "2        Izakaya             Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "3     Dining bar             Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "4    Cafe/Sweets  Shizuoka-ken Hamamatsu-shi Motoshirochō  34.710895   \n",
       "\n",
       "    longitude day_of_week holiday_flg  \n",
       "0  139.751599   Wednesday           0  \n",
       "1  139.725858   Wednesday           0  \n",
       "2  139.751599   Wednesday           0  \n",
       "3  139.751599   Wednesday           0  \n",
       "4  137.725940   Wednesday           0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tra_as_hol_0\"]=data[\"tra\"].merge(data[\"as\"],on=\"air_store_id\").merge(data[\"hol\"],left_on=\"visit_date\",right_on=\"calendar_date\").\\\n",
    "                    drop(\"calendar_date\",axis=1)\n",
    "data[\"tra_as_hol_0\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>genre_wht_mean_dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3.581434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3.383633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>3.678748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3.721482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3.337306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  air_genre_name day_of_week  genre_wht_mean_dow\n",
       "0          Asian      Friday            3.581434\n",
       "1          Asian      Monday            3.383633\n",
       "2          Asian    Saturday            3.678748\n",
       "3          Asian      Sunday            3.721482\n",
       "4          Asian    Thursday            3.337306"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_mean_dow=pd.DataFrame()\n",
    "#genre_mean_dow[\"genre_mean_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"day_of_week\"]).visitors.mean()\n",
    "#genre_mean_dow[\"genre_median_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"day_of_week\"]).visitors.median()\n",
    "#genre_mean_dow[\"genre_min_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"day_of_week\"]).visitors.min()\n",
    "#genre_mean_dow[\"genre_max_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"day_of_week\"]).visitors.max()\n",
    "#genre_mean_dow[\"genre_std_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"day_of_week\"]).visitors.std()\n",
    "genre_mean_dow[\"genre_wht_mean_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"day_of_week\"]).apply(lambda x: np.average(x['visitors'], weights=x['weights']))\n",
    "\n",
    "genre_mean_dow.reset_index(inplace=True)\n",
    "genre_mean_dow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>genre_wht_mean_hol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>3.512910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>1</td>\n",
       "      <td>3.499244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bar/Cocktail</td>\n",
       "      <td>0</td>\n",
       "      <td>2.338968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bar/Cocktail</td>\n",
       "      <td>1</td>\n",
       "      <td>2.531758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cafe/Sweets</td>\n",
       "      <td>0</td>\n",
       "      <td>2.889065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  air_genre_name  holiday_flg  genre_wht_mean_hol\n",
       "0          Asian            0            3.512910\n",
       "1          Asian            1            3.499244\n",
       "2   Bar/Cocktail            0            2.338968\n",
       "3   Bar/Cocktail            1            2.531758\n",
       "4    Cafe/Sweets            0            2.889065"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_mean_hol=pd.DataFrame()\n",
    "#genre_mean_hol[\"genre_mean_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"holiday_flg\"]).visitors.mean()\n",
    "#genre_mean_hol[\"genre_median_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"holiday_flg\"]).visitors.median()\n",
    "#genre_mean_hol[\"genre_min_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"holiday_flg\"]).visitors.min()\n",
    "#genre_mean_hol[\"genre_max_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"holiday_flg\"]).visitors.max()\n",
    "#genre_mean_hol[\"genre_std_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"holiday_flg\"]).visitors.std()\n",
    "genre_mean_hol[\"genre_wht_mean_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_genre_name\",\"holiday_flg\"]).apply(lambda x: np.average(x['visitors'], weights=x['weights']))\n",
    "\n",
    "\n",
    "genre_mean_hol.reset_index(inplace=True)\n",
    "genre_mean_hol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>area_wht_mean_dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Daimyō</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2.847578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Daimyō</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2.636426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Daimyō</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>3.049685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Daimyō</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2.881511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Daimyō</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2.677424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_area_name day_of_week  area_wht_mean_dow\n",
       "0  Fukuoka-ken Fukuoka-shi Daimyō      Friday           2.847578\n",
       "1  Fukuoka-ken Fukuoka-shi Daimyō      Monday           2.636426\n",
       "2  Fukuoka-ken Fukuoka-shi Daimyō    Saturday           3.049685\n",
       "3  Fukuoka-ken Fukuoka-shi Daimyō      Sunday           2.881511\n",
       "4  Fukuoka-ken Fukuoka-shi Daimyō    Thursday           2.677424"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_mean_dow=pd.DataFrame()\n",
    "#area_mean_dow[\"area_mean_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"day_of_week\"]).visitors.mean()\n",
    "#area_mean_dow[\"area_median_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"day_of_week\"]).visitors.median()\n",
    "#area_mean_dow[\"area_min_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"day_of_week\"]).visitors.min()\n",
    "#area_mean_dow[\"area_max_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"day_of_week\"]).visitors.max()\n",
    "#area_mean_dow[\"area_std_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"day_of_week\"]).visitors.std()\n",
    "area_mean_dow[\"area_wht_mean_dow\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"day_of_week\"]).apply(lambda x: np.average(x['visitors'], weights=x['weights']))\n",
    "\n",
    "area_mean_dow.reset_index(inplace=True)\n",
    "area_mean_dow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>area_wht_mean_hol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Daimyō</td>\n",
       "      <td>0</td>\n",
       "      <td>2.764310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Daimyō</td>\n",
       "      <td>1</td>\n",
       "      <td>2.904366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Hakata Ekimae</td>\n",
       "      <td>0</td>\n",
       "      <td>2.852027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Hakata Ekimae</td>\n",
       "      <td>1</td>\n",
       "      <td>2.953138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fukuoka-ken Fukuoka-shi Imaizumi</td>\n",
       "      <td>0</td>\n",
       "      <td>2.670225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           air_area_name  holiday_flg  area_wht_mean_hol\n",
       "0         Fukuoka-ken Fukuoka-shi Daimyō            0           2.764310\n",
       "1         Fukuoka-ken Fukuoka-shi Daimyō            1           2.904366\n",
       "2  Fukuoka-ken Fukuoka-shi Hakata Ekimae            0           2.852027\n",
       "3  Fukuoka-ken Fukuoka-shi Hakata Ekimae            1           2.953138\n",
       "4       Fukuoka-ken Fukuoka-shi Imaizumi            0           2.670225"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_mean_hol=pd.DataFrame()\n",
    "#area_mean_hol[\"area_mean_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"holiday_flg\"]).visitors.mean()\n",
    "#area_mean_hol[\"area_median_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"holiday_flg\"]).visitors.median()\n",
    "#area_mean_hol[\"area_min_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"holiday_flg\"]).visitors.min()\n",
    "#area_mean_hol[\"area_max_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"holiday_flg\"]).visitors.max()\n",
    "#area_mean_hol[\"area_std_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"holiday_flg\"]).visitors.std()\n",
    "area_mean_hol[\"area_wht_mean_hol\"]=data[\"tra_as_hol_0\"].groupby([\"air_area_name\",\"holiday_flg\"]).apply(lambda x: np.average(x['visitors'], weights=x['weights']))\n",
    "\n",
    "area_mean_hol.reset_index(inplace=True)\n",
    "area_mean_hol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train + day info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>month</th>\n",
       "      <th>time_numeric</th>\n",
       "      <th>weights</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_25e9888d30b386df</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fd6aac1043520e83</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_64d4491ad8cdb1c6</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ee3a01f0c71a769f</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1.025476</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id visit_date  visitors month  time_numeric   weights  \\\n",
       "0  air_ba937bf13d40fb24 2016-01-13  3.258097     1        1036.8  1.025476   \n",
       "1  air_25e9888d30b386df 2016-01-13  3.091042     1        1036.8  1.025476   \n",
       "2  air_fd6aac1043520e83 2016-01-13  3.713572     1        1036.8  1.025476   \n",
       "3  air_64d4491ad8cdb1c6 2016-01-13  1.791759     1        1036.8  1.025476   \n",
       "4  air_ee3a01f0c71a769f 2016-01-13  2.944439     1        1036.8  1.025476   \n",
       "\n",
       "  day_of_week holiday_flg  \n",
       "0   Wednesday           0  \n",
       "1   Wednesday           0  \n",
       "2   Wednesday           0  \n",
       "3   Wednesday           0  \n",
       "4   Wednesday           0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tra_hol\"]=data[\"tra\"].merge(data[\"hol\"],left_on=\"visit_date\",right_on=\"calendar_date\").\\\n",
    "            drop(\"calendar_date\",axis=1)\n",
    "data[\"tra_hol\"][\"month\"]=data[\"tra_hol\"].visit_date.map(lambda x: x.month)\n",
    "data[\"tra_hol\"][\"month\"]=data[\"tra_hol\"][\"month\"].astype('category')\n",
    "data[\"tra_hol\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>store_wht_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>3.181034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>2.110157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>2.217256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_0328696196e46f18</td>\n",
       "      <td>1.970034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_034a3d5b40d5b1b1</td>\n",
       "      <td>2.512139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  store_wht_mean\n",
       "0  air_00a91d42b08b08d9        3.181034\n",
       "1  air_0164b9927d20bcc3        2.110157\n",
       "2  air_0241aa3964b7f861        2.217256\n",
       "3  air_0328696196e46f18        1.970034\n",
       "4  air_034a3d5b40d5b1b1        2.512139"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_mean_0=pd.DataFrame()\n",
    "#store_mean_0[\"store_mean\"]=data[\"tra\"].groupby(\"air_store_id\").visitors.mean()\n",
    "#store_mean_0[\"store_median\"]=data[\"tra\"].groupby(\"air_store_id\").visitors.median()\n",
    "#store_mean_0[\"store_min\"]=data[\"tra\"].groupby(\"air_store_id\").visitors.min()\n",
    "#store_mean_0[\"store_max\"]=data[\"tra\"].groupby(\"air_store_id\").visitors.max()\n",
    "#store_mean_0[\"store_std\"]=data[\"tra\"].groupby(\"air_store_id\").visitors.std()\n",
    "store_mean_0[\"store_wht_mean\"]=data[\"tra\"].groupby(\"air_store_id\").apply(lambda x: np.average(x['visitors'], weights=x['weights']))\n",
    "\n",
    "store_mean_0.reset_index(inplace=True)\n",
    "store_mean_0.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>store_wht_mean_dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3.591833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3.081793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2.518185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3.412108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id day_of_week  store_wht_mean_dow\n",
       "0  air_00a91d42b08b08d9      Friday            3.591833\n",
       "1  air_00a91d42b08b08d9      Monday            3.081793\n",
       "2  air_00a91d42b08b08d9    Saturday            2.518185\n",
       "3  air_00a91d42b08b08d9      Sunday            1.098612\n",
       "4  air_00a91d42b08b08d9    Thursday            3.412108"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_mean_dow=pd.DataFrame()\n",
    "#store_mean_dow[\"store_dow_mdn\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\"]).visitors.median() #.reset_index()\n",
    "#store_mean_dow[\"store_dow_mean\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\"]).visitors.mean() #.reset_index()\n",
    "#store_mean_dow[\"store_dow_min\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\"]).visitors.min() #.reset_index()\n",
    "#store_mean_dow[\"store_dow_max\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\"]).visitors.max() #.reset_index()\n",
    "#store_mean_dow[\"store_dow_std\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\"]).visitors.std() #.reset_index()\n",
    "store_mean_dow[\"store_wht_mean_dow\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\"]).apply(lambda x: np.average(x['visitors'], weights=x['weights']))\n",
    "store_mean_dow[\"store_wht_mean_dow\"].fillna(store_mean_0[\"store_wht_mean\"],inplace=True)\n",
    "#store_mean_dow[\"store_dow_mdn\"].fillna(store_mean_0[\"store_median\"],inplace=True)\n",
    "#store_mean_dow[\"store_dow_mean\"].fillna(store_mean_0[\"store_mean\"],inplace=True)\n",
    "#store_mean_dow[\"store_dow_min\"].fillna(store_mean_0[\"store_min\"],inplace=True)\n",
    "#store_mean_dow[\"store_dow_max\"].fillna(store_mean_0[\"store_max\"],inplace=True)\n",
    "#store_mean_dow[\"store_dow_std\"].fillna(store_mean_0[\"store_std\"],inplace=True)\n",
    "#store_mean_dow.fillna(0,inplace=True)\n",
    "#store_mean_dow=store_mean_dow.drop(\"visitors\",axis=1)\n",
    "store_mean_dow=store_mean_dow.reset_index() #unstack(level=1)\n",
    "store_mean_dow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>store_wht_mean_dow_hol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>3.591833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>3.081579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.091042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>2.518185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id day_of_week  holiday_flg  store_wht_mean_dow_hol\n",
       "0  air_00a91d42b08b08d9      Friday            0                3.591833\n",
       "1  air_00a91d42b08b08d9      Monday            0                3.081579\n",
       "2  air_00a91d42b08b08d9      Monday            1                3.091042\n",
       "3  air_00a91d42b08b08d9    Saturday            0                2.518185\n",
       "4  air_00a91d42b08b08d9      Sunday            0                1.098612"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_mean_dow_hol=pd.DataFrame()\n",
    "#store_mean_dow_hol[\"store_dow_hol_mdn\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\",'holiday_flg']).visitors.median() #.reset_index()\n",
    "#store_mean_dow_hol[\"store_dow_hol_mean\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\",'holiday_flg']).visitors.mean() #.reset_index()\n",
    "#store_mean_dow_hol[\"store_dow_hol_min\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\",'holiday_flg']).visitors.min() #.reset_index()\n",
    "#store_mean_dow_hol[\"store_dow_hol_max\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\",'holiday_flg']).visitors.max() #.reset_index()\n",
    "#store_mean_dow_hol[\"store_dow_hol_std\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\",'holiday_flg']).visitors.std() #.reset_index()\n",
    "\n",
    "store_mean_dow_hol[\"store_wht_mean_dow_hol\"]=data[\"tra_hol\"].groupby([\"air_store_id\",\"day_of_week\",'holiday_flg']).apply(lambda x: np.average(x['visitors'], weights=x['weights']))\n",
    "store_mean_dow_hol[\"store_wht_mean_dow_hol\"].fillna(store_mean_dow[\"store_wht_mean_dow\"],inplace=True)\n",
    "\n",
    "#store_mean_dow_hol[\"store_dow_hol_mdn\"].fillna(store_mean_dow[\"store_dow_mdn\"],inplace=True)\n",
    "#store_mean_dow_hol[\"store_dow_hol_mean\"].fillna(store_mean_dow[\"store_dow_mean\"],inplace=True)\n",
    "#store_mean_dow_hol[\"store_dow_hol_min\"].fillna(store_mean_dow[\"store_dow_min\"],inplace=True)\n",
    "#store_mean_dow_hol[\"store_dow_hol_max\"].fillna(store_mean_dow[\"store_dow_max\"],inplace=True)\n",
    "#store_mean_dow_hol[\"store_dow_hol_std\"].fillna(store_mean_dow[\"store_dow_std\"],inplace=True)\n",
    "store_mean_dow_hol=store_mean_dow_hol.fillna(0)\n",
    "#store_mean_dow=store_mean_dow.drop(\"visitors\",axis=1)\n",
    "store_mean_dow_hol=store_mean_dow_hol.reset_index() #unstack(level=1)\n",
    "store_mean_dow_hol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train +store info + store mean + day info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air_store_id</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_numeric</th>\n",
       "      <td>1036.8</td>\n",
       "      <td>1641.6</td>\n",
       "      <td>2246.4</td>\n",
       "      <td>2851.2</td>\n",
       "      <td>3456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <td>2016-01-13 00:00:00</td>\n",
       "      <td>2016-01-20 00:00:00</td>\n",
       "      <td>2016-01-27 00:00:00</td>\n",
       "      <td>2016-02-03 00:00:00</td>\n",
       "      <td>2016-02-10 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors</th>\n",
       "      <td>3.2581</td>\n",
       "      <td>3.46574</td>\n",
       "      <td>3.21888</td>\n",
       "      <td>2.94444</td>\n",
       "      <td>3.49651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>1.02548</td>\n",
       "      <td>1.04064</td>\n",
       "      <td>1.05602</td>\n",
       "      <td>1.07163</td>\n",
       "      <td>1.08747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday_flg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_wht_mean_dow</th>\n",
       "      <td>3.09737</td>\n",
       "      <td>3.09737</td>\n",
       "      <td>3.09737</td>\n",
       "      <td>3.09737</td>\n",
       "      <td>3.09737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_wht_mean_dow_hol</th>\n",
       "      <td>3.11376</td>\n",
       "      <td>3.11376</td>\n",
       "      <td>3.11376</td>\n",
       "      <td>3.11376</td>\n",
       "      <td>3.11376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name</th>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Dining bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_area_name</th>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>35.6581</td>\n",
       "      <td>35.6581</td>\n",
       "      <td>35.6581</td>\n",
       "      <td>35.6581</td>\n",
       "      <td>35.6581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>139.752</td>\n",
       "      <td>139.752</td>\n",
       "      <td>139.752</td>\n",
       "      <td>139.752</td>\n",
       "      <td>139.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_wht_mean</th>\n",
       "      <td>2.97155</td>\n",
       "      <td>2.97155</td>\n",
       "      <td>2.97155</td>\n",
       "      <td>2.97155</td>\n",
       "      <td>2.97155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_wht_mean</th>\n",
       "      <td>2.72148</td>\n",
       "      <td>2.72148</td>\n",
       "      <td>2.72148</td>\n",
       "      <td>2.72148</td>\n",
       "      <td>2.72148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_wht_mean_dow</th>\n",
       "      <td>2.7831</td>\n",
       "      <td>2.7831</td>\n",
       "      <td>2.7831</td>\n",
       "      <td>2.7831</td>\n",
       "      <td>2.7831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_wht_mean_hol</th>\n",
       "      <td>2.72481</td>\n",
       "      <td>2.72481</td>\n",
       "      <td>2.72481</td>\n",
       "      <td>2.72481</td>\n",
       "      <td>2.72481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_wht_mean_hol</th>\n",
       "      <td>2.63846</td>\n",
       "      <td>2.63846</td>\n",
       "      <td>2.63846</td>\n",
       "      <td>2.63846</td>\n",
       "      <td>2.63846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_wht_mean_dow</th>\n",
       "      <td>2.55846</td>\n",
       "      <td>2.55846</td>\n",
       "      <td>2.55846</td>\n",
       "      <td>2.55846</td>\n",
       "      <td>2.55846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_wht_mean</th>\n",
       "      <td>2.64216</td>\n",
       "      <td>2.64216</td>\n",
       "      <td>2.64216</td>\n",
       "      <td>2.64216</td>\n",
       "      <td>2.64216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "air_store_id                    air_ba937bf13d40fb24   \n",
       "month                                              1   \n",
       "time_numeric                                  1036.8   \n",
       "visit_date                       2016-01-13 00:00:00   \n",
       "visitors                                      3.2581   \n",
       "weights                                      1.02548   \n",
       "day_of_week                                Wednesday   \n",
       "holiday_flg                                        0   \n",
       "store_wht_mean_dow                           3.09737   \n",
       "store_wht_mean_dow_hol                       3.11376   \n",
       "air_genre_name                            Dining bar   \n",
       "air_area_name           Tōkyō-to Minato-ku Shibakōen   \n",
       "latitude                                     35.6581   \n",
       "longitude                                    139.752   \n",
       "store_wht_mean                               2.97155   \n",
       "area_wht_mean                                2.72148   \n",
       "area_wht_mean_dow                             2.7831   \n",
       "area_wht_mean_hol                            2.72481   \n",
       "genre_wht_mean_hol                           2.63846   \n",
       "genre_wht_mean_dow                           2.55846   \n",
       "genre_wht_mean                               2.64216   \n",
       "\n",
       "                                                   1  \\\n",
       "air_store_id                    air_ba937bf13d40fb24   \n",
       "month                                              1   \n",
       "time_numeric                                  1641.6   \n",
       "visit_date                       2016-01-20 00:00:00   \n",
       "visitors                                     3.46574   \n",
       "weights                                      1.04064   \n",
       "day_of_week                                Wednesday   \n",
       "holiday_flg                                        0   \n",
       "store_wht_mean_dow                           3.09737   \n",
       "store_wht_mean_dow_hol                       3.11376   \n",
       "air_genre_name                            Dining bar   \n",
       "air_area_name           Tōkyō-to Minato-ku Shibakōen   \n",
       "latitude                                     35.6581   \n",
       "longitude                                    139.752   \n",
       "store_wht_mean                               2.97155   \n",
       "area_wht_mean                                2.72148   \n",
       "area_wht_mean_dow                             2.7831   \n",
       "area_wht_mean_hol                            2.72481   \n",
       "genre_wht_mean_hol                           2.63846   \n",
       "genre_wht_mean_dow                           2.55846   \n",
       "genre_wht_mean                               2.64216   \n",
       "\n",
       "                                                   2  \\\n",
       "air_store_id                    air_ba937bf13d40fb24   \n",
       "month                                              1   \n",
       "time_numeric                                  2246.4   \n",
       "visit_date                       2016-01-27 00:00:00   \n",
       "visitors                                     3.21888   \n",
       "weights                                      1.05602   \n",
       "day_of_week                                Wednesday   \n",
       "holiday_flg                                        0   \n",
       "store_wht_mean_dow                           3.09737   \n",
       "store_wht_mean_dow_hol                       3.11376   \n",
       "air_genre_name                            Dining bar   \n",
       "air_area_name           Tōkyō-to Minato-ku Shibakōen   \n",
       "latitude                                     35.6581   \n",
       "longitude                                    139.752   \n",
       "store_wht_mean                               2.97155   \n",
       "area_wht_mean                                2.72148   \n",
       "area_wht_mean_dow                             2.7831   \n",
       "area_wht_mean_hol                            2.72481   \n",
       "genre_wht_mean_hol                           2.63846   \n",
       "genre_wht_mean_dow                           2.55846   \n",
       "genre_wht_mean                               2.64216   \n",
       "\n",
       "                                                   3  \\\n",
       "air_store_id                    air_ba937bf13d40fb24   \n",
       "month                                              2   \n",
       "time_numeric                                  2851.2   \n",
       "visit_date                       2016-02-03 00:00:00   \n",
       "visitors                                     2.94444   \n",
       "weights                                      1.07163   \n",
       "day_of_week                                Wednesday   \n",
       "holiday_flg                                        0   \n",
       "store_wht_mean_dow                           3.09737   \n",
       "store_wht_mean_dow_hol                       3.11376   \n",
       "air_genre_name                            Dining bar   \n",
       "air_area_name           Tōkyō-to Minato-ku Shibakōen   \n",
       "latitude                                     35.6581   \n",
       "longitude                                    139.752   \n",
       "store_wht_mean                               2.97155   \n",
       "area_wht_mean                                2.72148   \n",
       "area_wht_mean_dow                             2.7831   \n",
       "area_wht_mean_hol                            2.72481   \n",
       "genre_wht_mean_hol                           2.63846   \n",
       "genre_wht_mean_dow                           2.55846   \n",
       "genre_wht_mean                               2.64216   \n",
       "\n",
       "                                                   4  \n",
       "air_store_id                    air_ba937bf13d40fb24  \n",
       "month                                              2  \n",
       "time_numeric                                    3456  \n",
       "visit_date                       2016-02-10 00:00:00  \n",
       "visitors                                     3.49651  \n",
       "weights                                      1.08747  \n",
       "day_of_week                                Wednesday  \n",
       "holiday_flg                                        0  \n",
       "store_wht_mean_dow                           3.09737  \n",
       "store_wht_mean_dow_hol                       3.11376  \n",
       "air_genre_name                            Dining bar  \n",
       "air_area_name           Tōkyō-to Minato-ku Shibakōen  \n",
       "latitude                                     35.6581  \n",
       "longitude                                    139.752  \n",
       "store_wht_mean                               2.97155  \n",
       "area_wht_mean                                2.72148  \n",
       "area_wht_mean_dow                             2.7831  \n",
       "area_wht_mean_hol                            2.72481  \n",
       "genre_wht_mean_hol                           2.63846  \n",
       "genre_wht_mean_dow                           2.55846  \n",
       "genre_wht_mean                               2.64216  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df= data[\"tra_test\"].merge(data[\"hol\"],left_on=\"visit_date\",right_on=\"calendar_date\").\\\n",
    "                    drop(\"calendar_date\",axis=1).\\\n",
    "                    merge(store_mean_dow,on=[\"air_store_id\",\"day_of_week\"]).\\\n",
    "                    merge(store_mean_dow_hol,on=[\"air_store_id\",\"day_of_week\",'holiday_flg']).\\\n",
    "                    merge(data[\"as\"],on=[\"air_store_id\"]).\\\n",
    "                    merge(store_mean_0,on=[\"air_store_id\"]) .\\\n",
    "                    merge(area_mean_0,on=[\"air_area_name\"]).\\\n",
    "                    merge(area_mean_dow,on=[\"air_area_name\",\"day_of_week\"]) .\\\n",
    "                    merge(area_mean_hol,on=[\"air_area_name\",\"holiday_flg\"]) .\\\n",
    "                    merge(genre_mean_hol,on=[\"air_genre_name\",\"holiday_flg\"]).\\\n",
    "                    merge(genre_mean_dow,on=[\"air_genre_name\",\"day_of_week\"]).\\\n",
    "                    merge(genre_mean_0,on=[\"air_genre_name\"])\n",
    "final_df[\"month\"]=final_df.visit_date.map(lambda x: x.month)\n",
    "final_df[\"month\"]=final_df[\"month\"].astype('category')           \n",
    "\n",
    "final_df.head().T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for day of week, holiday, month, genre, area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "final_df[\"month\"]=final_df[\"month\"].astype('category')\n",
    "#data[\"tra_as_hol\"].dtypes\n",
    "cols_to_enc=[\"month\",\"day_of_week\",\"air_genre_name\", 'air_area_name']\n",
    "dummies=pd.get_dummies(final_df[cols_to_enc])\n",
    "#data[\"tra_as_hol\"].join(dummies)\n",
    "\n",
    "enc=final_df.join(dummies)\n",
    "enc=final_df\n",
    "\n",
    "enc=enc.drop(cols_to_enc,axis=1).drop([\"latitude\",\"longitude\"],axis=1)\n",
    "enc.head()\n",
    "#for c in enc.columns: print(c)\n",
    "print(len(enc.columns))\n",
    "#print(enc.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f64_to_32(df):\n",
    "    float_cols=df.select_dtypes(include=[\"float64\"]).columns\n",
    "    int_cols=df.select_dtypes(include=[\"int64\"]).columns\n",
    "    for fc in float_cols:\n",
    "        print(fc)\n",
    "        df[fc]=df[fc].astype(\"float32\")\n",
    "    for ic in int_cols:\n",
    "        print(ic)\n",
    "        df[ic]=df[ic].astype(\"int32\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.month.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f15ebdedb624>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mce\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinaryEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols_to_enc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0menc2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\category_encoders\\binary.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mordinal_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_invariant\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\category_encoders\\binary.py\u001b[0m in \u001b[0;36mbinary\u001b[1;34m(self, X_in, cols)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;31m# map the ordinal column into a list of these digits, of length digits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdig\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;31m# arg is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[1;32mpandas\\_libs\\src\\inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas\\_libs\\lib.c:66440)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\category_encoders\\binary.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;31m# map the ordinal column into a list of these digits, of length digits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdig\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\category_encoders\\binary.py\u001b[0m in \u001b[0;36mcol_transform\u001b[1;34m(col, digits)\u001b[0m\n\u001b[0;32m    226\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\category_encoders\\binary.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    226\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(cols=cols_to_enc)\n",
    "enc2=encoder.fit_transform(final_df)\n",
    "\n",
    "print(sys.getsizeof(enc2)/1024/1024)\n",
    "f64_to_32(enc2)\n",
    "print(sys.getsizeof(enc2)/1024/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide train-test before-after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train,df_test,df_eval=train_test_eval(enc,cut_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df_train.groupby(\"visit_date\")[\"visitors\"].mean().plot()\n",
    "df_test.groupby(\"visit_date\")[\"visitors\"].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "len(final_df[\"air_area_name\"].unique()),\n",
    "len(final_df[\"longitude\"].unique()),\n",
    "len(final_df[\"latitude\"].unique()),\n",
    ")\n",
    "print(\n",
    "len(final_df.groupby(['latitude', 'longitude']).size()),\n",
    "len(final_df.groupby([\"air_area_name\",'latitude', 'longitude']).size())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each store I use mean, min, max, std, area, genre, day and holiday as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xy_train_test(df_train,df_test):\n",
    "    try:\n",
    "        X_train = df_train.drop([\"visitors\",\"visit_date\",\"air_store_id\",\"latitude\",\"longitude\"],axis=1).as_matrix()\n",
    "        X_test =  df_test.drop([\"visitors\",\"visit_date\",\"air_store_id\",\"latitude\",\"longitude\"],axis=1).as_matrix()\n",
    "    except:\n",
    "        #try:\n",
    "            X_train = df_train.drop([\"visitors\",\"visit_date\",\"air_store_id\"],axis=1).as_matrix()\n",
    "            X_test =  df_test.drop([\"visitors\",\"visit_date\",\"air_store_id\"],axis=1).as_matrix()\n",
    "        #except: \n",
    "        #            try:\n",
    "        #                X_train = df_train.drop([\"col_visitors\",\"col_visit_date\",\"col_air_store_id\",\"col_latitude\",\"col_longitude\"],axis=1).as_matrix()\n",
    "        #                X_test =  df_test.drop([\"col_visitors\",\"col_visit_date\",\"col_air_store_id\",\"col_latitude\",\"col_longitude\"],axis=1).as_matrix()\n",
    "        #            except:\n",
    "        #                X_train = df_train.drop([\"col_visitors\",\"col_visit_date\",\"col_air_store_id\"],axis=1).as_matrix()\n",
    "        #                X_test =  df_test.drop([\"col_visitors\",\"col_visit_date\",\"col_air_store_id\"],axis=1).as_matrix()\"\"\"\n",
    "    # Split the targets into training/testing sets\n",
    "    try:\n",
    "        y_train = df_train[\"visitors\"].values\n",
    "        y_test =  df_test[\"visitors\"].values\n",
    "    except:\n",
    "        y_train = df_train[\"col_visitors\"].values\n",
    "        y_test =  df_test[\"col_visitors\"].values\n",
    "        \n",
    "    #return(X_train,X_test,y_train,y_test)              \n",
    "    return(X_train.astype(\"float32\"),X_test.astype(\"float32\"),y_train.astype(\"float32\"),y_test.astype(\"float32\"))              \n",
    "\n",
    "\n",
    "def test(df_train,df_test,regr):\n",
    "    #print(df_train.columns)\n",
    "\n",
    "    (X_train,X_test,y_train,y_test) = xy_train_test(df_train,df_test)\n",
    "\n",
    "    #print(X_train.shape,y_train.shape)\n",
    "    #print(X_test.shape,y_test.shape)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred_train = regr.predict(X_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    y_pred=np.maximum(0,y_pred)\n",
    "    y_pred_train=np.maximum(0,y_pred_train)\n",
    "    error=RMSE(y_test, y_pred)\n",
    "    error_train=RMSE(y_train, y_pred_train)\n",
    "    print(error,error_train)\n",
    "    return error,error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train,X_test,y_train,y_test) = xy_train_test(df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(enc.columns),len(enc2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train,df_test,df_eval=train_test_eval(enc,cut_date)\n",
    "test(df_train,df_test, linear_model.LinearRegression())\n",
    "df_train,df_test,df_eval=train_test_eval(enc2,cut_date)\n",
    "test(df_train,df_test, linear_model.LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoder = ce.BinaryEncoder(cols=cols_to_enc)\n",
    "#enc2=encoder.fit_transform(data[\"tra_as_hol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train,df_test,df_eval=train_test_eval(enc2,cut_date)\n",
    "df_train,df_test,df_eval=train_test_eval(enc2,cut_date)\n",
    "\n",
    "test(df_train,df_test, linear_model.LinearRegression())\n",
    "test(df_train,df_test, linear_model.Ridge(alpha=0.001))\n",
    "test(df_train,df_test, linear_model.Ridge(alpha=0.01))\n",
    "test(df_train,df_test, linear_model.Ridge(alpha=0.1))\n",
    "test(df_train,df_test, linear_model.Ridge(alpha=1))\n",
    "test(df_train,df_test, linear_model.Ridge(alpha=10))\n",
    "test(df_train,df_test, linear_model.Ridge(alpha=100))\n",
    "test(df_train,df_test, linear_model.Ridge(alpha=1000))\n",
    "#test(df_train,df_test, linear_model.Lasso(alpha=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#test(df_train,df_test, svm.SVR(C=0.01))\n",
    "#test(df_train,df_test, svm.SVR(C=0.1))\n",
    "#test(df_train,df_test, svm.SVR(C=1))\n",
    "#test(df_train,df_test, svm.SVR(C=10))\n",
    "#test(df_train,df_test, svm.SVR(C=100))\n",
    "\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"sqrt\",max_depth=20))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=5,max_features=\"sqrt\",max_depth=20))\n",
    "#test(df_train,df_test,ensemble.AdaBoostRegressor)\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=200,max_features=\"log2\",max_depth=10))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=16))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=15))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=14))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=13))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=12))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=11))\n",
    "test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=10))\n",
    "test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=9))\n",
    "test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=8))\n",
    "test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=7))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=90,max_features=\"log2\",max_depth=17))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=120,max_features=\"log2\",max_depth=13))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=80,max_features=\"log2\",max_depth=18))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=150,max_features=\"log2\",max_depth=12))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=180,max_features=\"log2\",max_depth=10))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=80,max_features=\"log2\",max_depth=15))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=15))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=14))\n",
    "\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=14))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=13))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=200,max_features=\"log2\",max_depth=15))\n",
    "#test(df_train,df_test,ensemble.RandomForestRegressor(n_estimators=500,max_features=\"log2\",max_depth=15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "test_fold=np.append(-np.ones(len(df_train)),np.zeros(len(df_test)))\n",
    "ps = PredefinedSplit(test_fold)\n",
    "ps.get_n_splits()\n",
    "print(ps)       \n",
    "for train_index, test_index in ps.split():\n",
    "    print(len(train_index),len(test_index))\n",
    "    print(len(df_train),len(df_test))\n",
    "    print(train_index,test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from  sklearn.model_selection import RandomizedSearchCV\n",
    "grid=RandomizedSearchCV(ensemble.RandomForestRegressor(), \n",
    "                                        param_distributions=\n",
    "                        {\"max_depth\": scipy.stats.randint(5,20), \n",
    "                         'n_estimators': scipy.stats.randint(50,250),\n",
    "                        'max_features':('log2','sqrt')},\n",
    "                                        n_iter=10,verbose=10,cv=ps,scoring=\"neg_mean_squared_error\" )\n",
    "\n",
    "(X_train,X_test,y_train,y_test) = xy_train_test(df_train,df_test)\n",
    "X_tot=np.append(X_train,X_test,axis=0)\n",
    "y_tot=np.append(y_train,y_test,axis=0)\n",
    "\n",
    "grid.fit(X_tot,y_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_,np.sqrt(-grid.best_score_),grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test(df_train,df_test,ensemble.GradientBoostingRegressor(loss=\"ls\", learning_rate=1, n_estimators=50,max_depth=5))\n",
    "test(df_train,df_test,ensemble.GradientBoostingRegressor(loss=\"ls\", learning_rate=1, n_estimators=100,max_depth=5))\n",
    "#test(df_train,df_test,ensemble.GradientBoostingRegressor(loss=\"ls\", learning_rate=1, n_estimators=50,max_depth=10))\n",
    "#test(df_train,df_test,ensemble.GradientBoostingRegressor(loss=\"ls\", learning_rate=1, n_estimators=100,max_depth=10))\n",
    "#test(df_train,df_test,ensemble.AdaBoostRegressor(n_estimators=100, learning_rate=0.5, loss=\"square\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "for rate in 0.1,:\n",
    "    print(rate)\n",
    "    test(df_train,df_test,XGBRegressor(max_depth=10, learning_rate=rate, n_estimators=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PredefinedSplit(test_fold=your_test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lognuniform(low=0, high=1, size=None, base=10):\n",
    "    return np.power(base, np.random.uniform(low, high, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=lognuniform(low=-4,high=0,size=10,base=10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "\n",
    "grid=model_selection.RandomizedSearchCV(XGBRegressor(), \n",
    "                                        param_distributions={\n",
    "                        \"max_depth\": scipy.stats.randint(2,10), \n",
    "                         'n_estimators': scipy.stats.randint(50,400),\n",
    "                         'learning_rate':lognuniform(low=-1.5,high=-0.5,base=10,size=100),\n",
    "                        }, \n",
    "                                        n_iter=100,verbose=10 ,cv=ps,scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "(X_train,X_test,y_train,y_test) = xy_train_test(df_train,df_test)\n",
    "\n",
    "X_tot=np.append(X_train,X_test,axis=0)\n",
    "y_tot=np.append(y_train,y_test,axis=0)\n",
    "\n",
    "\n",
    "grid.fit(X_tot,y_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(-grid.best_score_),grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test(df_train,df_test,XGBRegressor(learning_rate=0.1, n_estimators=89,max_depth=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_csv(df_train,df_test,df_eval,regr,file):\n",
    "    df_train_tot=df_train.append(df_test)\n",
    "    print(df_train_tot.columns)\n",
    "    print(df_eval.columns)\n",
    "    X_train = df_train_tot.drop([\"visitors\",\"visit_date\",\"air_store_id\",\"latitude\",\"longitude\"],axis=1).as_matrix()\n",
    "    X_test =  df_eval.drop([\"visitors\",\"visit_date\",\"air_store_id\",\"latitude\",\"longitude\"],axis=1).as_matrix()\n",
    "    # Split the targets into training/testing sets\n",
    "    y_train = df_train_tot[\"visitors\"].values\n",
    "    print(X_train.shape,y_train.shape)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    y_pred=np.maximum(0,y_pred)\n",
    "    y_pred=np.expm1(y_pred)\n",
    "    df_eval[\"visitors\"]=y_pred\n",
    "    df_eval[\"id\"]=df_eval[\"air_store_id\"].map(str)+\"_\"+df_eval[\"visit_date\"].dt.strftime('%Y-%m-%d')\n",
    "    df_sub=df_eval[[\"id\",\"visitors\"]]\n",
    "    df_sub.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_eval=enc[enc.visitors.isna()]  \n",
    "make_csv(df_train,df_test,df_eval,linear_model.LinearRegression(),\"linear_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train,df_test,df_eval=train_test_eval(enc2,cut_date)\n",
    "make_csv(df_train,df_test,df_eval,ensemble.RandomForestRegressor(n_estimators=90,max_features=\"log2\",max_depth=18),\n",
    "         \"random_f_binary_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train,df_test,df_eval=train_test_eval(enc2,cut_date)\n",
    "make_csv(df_train,df_test,df_eval,XGBRegressor(learning_rate=0.12, n_estimators=300,max_depth=2),\n",
    "         \"xgb_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train,df_test,df_eval=train_test_eval(enc2,cut_date)\n",
    "make_csv(df_train,df_test,df_eval,ensemble.RandomForestRegressor(n_estimators=100,max_features=\"log2\",max_depth=16),\n",
    "         \"forest.csv\")\n",
    "#df_train,df_test,df_eval=train_test_eval(enc2,cut_date)\n",
    "#make_csv(df_train,df_test,df_eval,ensemble.RandomForestRegressor(n_estimators=150,max_features=\"log2\",max_depth=7),\n",
    "#         \"forest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=data[\"tes\"].merge(data[\"hol\"],left_on=\"time\",right_on=\"calendar_date\").\\\n",
    "            drop(\"time\",axis=1).\\\n",
    "            merge(data[\"as\"],right_on=\"air_store_id\",left_on=\"store_id\").\\\n",
    "            drop([\"store_id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test[\"month\"]=df_test.calendar_date.map(lambda x: x.month)\n",
    "df_test[\"month\"]=df_test[\"month\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cols_to_enc=[\"holiday_flg\",\"air_genre_name\",\"air_area_name\",\"day_of_week\"]\n",
    "cols_to_enc=[\"month\",\"holiday_flg\",\"day_of_week\",\"air_genre_name\", 'air_area_name']\n",
    "dummies=pd.get_dummies(df_test[cols_to_enc])\n",
    "#data[\"tra_as_hol\"].join(dummies)\n",
    "df_test=df_test.join(dummies)\n",
    "#enc.describe()\n",
    "df_test=df_test.drop(cols_to_enc,axis=1).drop([\"air_store_id\",\"latitude\",\"longitude\"],axis=1)\n",
    "enc.head()\n",
    "for c in df_test.columns: print(c)\n",
    "print(len(df_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#total number of reservations per day, for a stores\n",
    "data[\"ar\"][\"visit_date\"]=data[\"ar\"][\"visit_datetime\"].map(lambda x:x.date())\n",
    "data[\"ar\"][\"visit_date\"]=pd.to_datetime(data[\"ar\"][\"visit_date\"])\n",
    "#data[\"ar\"].groupby(\"air_store_id\",\"visit_date\")[\"reserve_visitors\"].sum()\n",
    "\n",
    "#data[\"ar\"]\n",
    "data[\"ar_sum\"]=data[\"ar\"].groupby([\"air_store_id\",\"visit_date\"]) [\"reserve_visitors\"].sum().reset_index()\n",
    "data[\"ar_sum\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this contains only days with reservations\n",
    "data[\"tra_ar_sum\"]=data[\"ar_sum\"].merge(data[\"tra_as_hol\"],on=[\"visit_date\",\"air_store_id\"])\n",
    "data[\"tra_ar_sum\"].head()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cols_to_enc=[\"holiday_flg\",\"air_genre_name\",\"air_area_name\",\"day_of_week\"]\n",
    "cols_to_enc=[\"month\",\"holiday_flg\",\"day_of_week\",\"air_genre_name\", 'air_area_name']\n",
    "dummies=pd.get_dummies(data[\"tra_as_hol\"][cols_to_enc])\n",
    "#data[\"tra_as_hol\"].join(dummies)\n",
    "enc=data[\"tra_as_hol\"].join(dummies)\n",
    "#enc.describe()\n",
    "enc=enc.drop(cols_to_enc,axis=1).drop([\"air_store_id\",\"latitude\",\"longitude\"],axis=1)\n",
    "enc.head()\n",
    "for c in enc.columns: print(c)\n",
    "print(len(enc.columns))\n",
    "#print(enc.columns)\n",
    "df_train=enc[enc[\"visit_date\"]<cut_date]\n",
    "df_test= enc[enc[\"visit_date\"]>= cut_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "print(df_train.columns)\n",
    "X_train = df_train.drop([\"visitors\",\"visit_date\"],axis=1).as_matrix()\n",
    "X_test =  df_test.drop([\"visitors\",\"visit_date\"],axis=1).as_matrix()\n",
    "    # Split the targets into training/testing sets\n",
    "y_train = df_train[\"visitors\"].values\n",
    "y_test =  df_test[\"visitors\"].values\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred=np.maximum(0,y_pred)\n",
    "error=RMSLE(y_test, y_pred)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_store_test[[\"visitors\",\"visitors_predicted\"]]\n",
    "df_test[[\"visitors\",\"visitors_predicted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"visitors\",\"visit_date\"],axis=1).values\n",
    "X_test =  df_test.drop([\"visitors\",\"visit_date\"],axis=1).values\n",
    "# Split the targets into training/testing sets\n",
    "y_train = df_train[\"visitors\"].values\n",
    "y_test =  df_test[\"visitors\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"hr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores_tra=set(data[\"tra\"].air_store_id.unique())\n",
    "stores_ar=set(data[\"ar\"].air_store_id.unique())\n",
    "stores_hr=set(data[\"hr\"].hpg_store_id.unique())\n",
    "stores_as=set(data[\"as\"].air_store_id.unique())\n",
    "stores_hs=set(data[\"hs\"].hpg_store_id.unique())\n",
    "stores_id_a=set(data[\"id\"].air_store_id.unique())\n",
    "stores_id_h=set(data[\"id\"].hpg_store_id.unique())\n",
    "stores_tes=set(data[\"tes\"].store_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stores_tes-stores_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    len(stores_tra),len(stores_ar),len(stores_as),len(stores_id_a),\"\\n\",\n",
    "                    len(stores_hr),len(stores_hs),len(stores_id_h),\"\\n\",\n",
    "    len(stores_tes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"tra_as_hol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores_groups=data[\"tra_as_hol\"].groupby(\"air_store_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_test=stores_groups.get_group(\"air_00a91d42b08b08d9\")[[\"visit_date\",\"visitors\"]]\n",
    "series_test=series_test.set_index(series_test.visit_date).drop(\"visit_date\",axis=1).dropna()\n",
    "series_test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "model = ARIMA(series_test, order=(1,1,0))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())\n",
    "# plot residual errors\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "residuals.plot(kind='kde')\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fit.fittedvalues.plot()\n",
    "series_test.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOW HOL average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train,df_test,df_eval=train_test_eval(data[\"tra_as_hol\"],cut_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_pred(df_train,df_test):\n",
    "    mean_store_dow_hol=df_train.groupby([\"air_store_id\",\"day_of_week\",\"holiday_flg\"]).visitors.mean().reset_index()\n",
    "    mean_store_dow=df_train.groupby([\"air_store_id\",\"day_of_week\"]).visitors.mean().reset_index()\n",
    "    mean_store_hol=df_train.groupby([\"air_store_id\",\"holiday_flg\"]).visitors.mean().reset_index()\n",
    "    mean_store=df_train.groupby([\"air_store_id\"]).visitors.mean().reset_index()\n",
    "    df_1=df_test.merge(mean_store_dow_hol,on=[\"air_store_id\",\"day_of_week\",\"holiday_flg\"],how=\"left\")\n",
    "    df_2=df_test.merge(mean_store_hol,on=[\"air_store_id\",\"holiday_flg\"],how=\"left\")\n",
    "    df_3=df_test.merge(mean_store_dow,on=[\"air_store_id\",\"day_of_week\"],how=\"left\")\n",
    "    df_4=df_test.merge(mean_store,on=[\"air_store_id\"],how=\"left\")\n",
    "    y_pred_1=df_1.visitors_y.values\n",
    "    y_pred_2=df_2.visitors_y.values\n",
    "    y_pred_3=df_3.visitors_y.values\n",
    "    y_pred_4=df_4.visitors_y.values\n",
    "    y_test=df_1.visitors_x.values\n",
    "    for i,y in enumerate(y_pred_1):\n",
    "        if np.isnan(y): \n",
    "            if not np.isnan(y_pred_2[i]): y_pred_1[i]=y_pred_2[i]\n",
    "            else:\n",
    "                if not np.isnan(y_pred_3[i]): y_pred_1[i]=y_pred_3[i]\n",
    "                else:\n",
    "                    if not np.isnan(y_pred_4[i]):y_pred_1[i]=y_pred_4[i]\n",
    "                    else:y_pred_1[i]=0\n",
    "    return (y_test,y_pred_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test,y_pred=get_y_pred(df_train,df_test)\n",
    "y_train,y_pred_t=get_y_pred(df_train,df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(y_test),len(y_pred),len(y_train),len(y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RMSE(y_train,y_pred_t),RMSE(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
